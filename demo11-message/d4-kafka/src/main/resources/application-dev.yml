# mybatis-plus配置
mybatis-plus:
  configuration:
    # 打印日志信息
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl

spring:
  # Kafka 配置项，对应 KafkaProperties 配置类
  kafka:
    bootstrap-servers: 127.0.0.1:9092 # 指定 Kafka Broker 地址，可以设置多个，以逗号分隔
    # Kafka Producer 配置项
    producer:
      acks: 1 # 0-不应答。1-leader 应答。all-所有 leader 和 follower 应答。
      retries: 3 # 发送失败时，重试发送的次数
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 消息的 key 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # 消息的 value 的序列化

      # 批量发送消息相关配置
#      batch-size: 16384 # 每次批量发送消息的最大数量
#      buffer-memory: 33554432 # 每次批量发送消息的最大内存
#      properties:
#        linger:
#          ms: 30000 # 批处理延迟时间上限。这里配置为 30 * 1000 ms 过后，不管是否消息数量是否到达 batch-size 或者消息大小到达 buffer-memory 后，都直接发送一次请求。

    # Kafka Consumer 配置项
    consumer:
      # earliest：当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      auto-offset-reset: earliest # 设置消费者分组最初的消费进度为 earliest 。可参考博客 https://blog.csdn.net/lishuangzhe7047/article/details/74530417 理解
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer

      # 批量消费消息相关配置
#      fetch-max-wait: 10000 # poll 一次拉取的阻塞的最大时长，单位：毫秒。这里指的是阻塞拉取需要满足至少 fetch-min-size 大小的消息
#      fetch-min-size: 10 # poll 一次消息拉取的最小数据量，单位：字节
#      max-poll-records: 100 # poll 一次消息拉取的最大数量

      properties:
        spring:
          json:
            trusted:
              packages: com.chenmeng.project.message
    # Kafka Consumer Listener 监听器配置
    listener:
#      type: BATCH # 监听器类型，默认为 SINGLE ，只监听单条消息。这里我们配置 BATCH ，监听多条消息，批量消费
      concurrency: 10 # 每个消费者监听器最大并发数，默认为 1 。可以通过设置 n ，这样对于每个监听器就会使用 n 个线程消费消息，提高整体消费速度。详细可参考博客 https://www.jianshu.com/p/ad0e5424edbd 理解。


logging:
  level:
    org:
      springframework:
        kafka: ERROR # spring-kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别
      apache:
        kafka: ERROR # kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别
